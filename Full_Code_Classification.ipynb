{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Full Code Classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HabibRobbani/S2/blob/master/Full_Code_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDPFq52YVMW3",
        "colab_type": "code",
        "outputId": "bab74cbd-756f-4391-db85-eecb4afb216c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import backend as K"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDvpiPilXhzM",
        "colab_type": "text"
      },
      "source": [
        "AWAL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UhNrFHPLXmgL",
        "colab_type": "code",
        "outputId": "7e2504f1-2f68-4f1c-ed86-ce46c1a9b285",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "batch_size = 128 #Jumlah Training\n",
        "num_classes = 10\n",
        "epochs = 100\n",
        "\n",
        "img_rows, img_cols = 28, 28\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data() #ini ngeload data su"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEYgnH6zaPr_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#for i in range (0, 10):\n",
        " # plt.imshow(x_train[i],'gray')\n",
        "  #plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0lGYswEap_p",
        "colab_type": "code",
        "outputId": "c72d57ec-90ca-4ac9-e765-7c6d835f384f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "#preprocessing data sebelum masuk model\n",
        "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols,1)\n",
        "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "input_shape = (img_rows, img_cols, 1)\n",
        "print(np.shape(x_train))  #data train 60000/data test 10000"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDy_-QL9zoiV",
        "colab_type": "code",
        "outputId": "8e8b2a3d-db99-4758-c50e-ad70e954f0c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "#normalisai data (menyekalakan data)\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /=255\n",
        "x_test /=255\n",
        "print('x_train shape:', x_train.shape)\n",
        "print (x_train.shape[0], ' train samples')\n",
        "print (x_test.shape[0], 'test sample')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (60000, 28, 28, 1)\n",
            "60000  train samples\n",
            "10000 test sample\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNNDg3G30VPU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#standararisai label\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOC0QH0m0cTc",
        "colab_type": "code",
        "outputId": "e060786e-7be6-45a1-dc8b-90d663dcc62f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        }
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3,3),\n",
        "                 activation='relu',\n",
        "                 input_shape=input_shape))\n",
        "model.add(Conv2D(64, (3,3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0,25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0,5))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 24, 24, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 9216)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               1179776   \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 1,199,882\n",
            "Trainable params: 1,199,882\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JgsUG8q21GVg",
        "colab_type": "code",
        "outputId": "74ace944-44ce-434f-c458-4eac12a505c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adadelta(), metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3BGB16h1gHq",
        "colab_type": "code",
        "outputId": "1956f021-7dee-4d59-c56d-dbf3138df199",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(x_train, y_train, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(x_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/100\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "60000/60000 [==============================] - 17s 289us/step - loss: 0.1929 - acc: 0.9405 - val_loss: 0.0529 - val_acc: 0.9835\n",
            "Epoch 2/100\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 0.0446 - acc: 0.9866 - val_loss: 0.0381 - val_acc: 0.9881\n",
            "Epoch 3/100\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 0.0279 - acc: 0.9917 - val_loss: 0.0290 - val_acc: 0.9898\n",
            "Epoch 4/100\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 0.0192 - acc: 0.9940 - val_loss: 0.0311 - val_acc: 0.9893\n",
            "Epoch 5/100\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0132 - acc: 0.9960 - val_loss: 0.0354 - val_acc: 0.9886\n",
            "Epoch 6/100\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 0.0087 - acc: 0.9974 - val_loss: 0.0321 - val_acc: 0.9905\n",
            "Epoch 7/100\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 0.0057 - acc: 0.9985 - val_loss: 0.0349 - val_acc: 0.9896\n",
            "Epoch 8/100\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 0.0044 - acc: 0.9987 - val_loss: 0.0303 - val_acc: 0.9912\n",
            "Epoch 9/100\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 0.0029 - acc: 0.9992 - val_loss: 0.0346 - val_acc: 0.9907\n",
            "Epoch 10/100\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 0.0023 - acc: 0.9993 - val_loss: 0.0363 - val_acc: 0.9899\n",
            "Epoch 11/100\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 0.0015 - acc: 0.9996 - val_loss: 0.0389 - val_acc: 0.9900\n",
            "Epoch 12/100\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 9.4779e-04 - acc: 0.9998 - val_loss: 0.0400 - val_acc: 0.9908\n",
            "Epoch 13/100\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 7.5711e-04 - acc: 0.9998 - val_loss: 0.0391 - val_acc: 0.9911\n",
            "Epoch 14/100\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 6.2668e-04 - acc: 0.9999 - val_loss: 0.0401 - val_acc: 0.9911\n",
            "Epoch 15/100\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 3.6058e-04 - acc: 1.0000 - val_loss: 0.0405 - val_acc: 0.9915\n",
            "Epoch 16/100\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 3.1951e-04 - acc: 1.0000 - val_loss: 0.0422 - val_acc: 0.9915\n",
            "Epoch 17/100\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 3.0338e-04 - acc: 1.0000 - val_loss: 0.0435 - val_acc: 0.9913\n",
            "Epoch 18/100\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 3.0235e-04 - acc: 1.0000 - val_loss: 0.0441 - val_acc: 0.9915\n",
            "Epoch 19/100\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 2.9111e-04 - acc: 1.0000 - val_loss: 0.0442 - val_acc: 0.9912\n",
            "Epoch 20/100\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 2.8575e-04 - acc: 1.0000 - val_loss: 0.0447 - val_acc: 0.9911\n",
            "Epoch 21/100\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 2.8412e-04 - acc: 1.0000 - val_loss: 0.0451 - val_acc: 0.9912\n",
            "Epoch 22/100\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 2.8251e-04 - acc: 1.0000 - val_loss: 0.0457 - val_acc: 0.9912\n",
            "Epoch 23/100\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 2.8105e-04 - acc: 1.0000 - val_loss: 0.0461 - val_acc: 0.9912\n",
            "Epoch 24/100\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 2.7975e-04 - acc: 1.0000 - val_loss: 0.0464 - val_acc: 0.9911\n",
            "Epoch 25/100\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 2.7888e-04 - acc: 1.0000 - val_loss: 0.0468 - val_acc: 0.9913\n",
            "Epoch 26/100\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 2.7818e-04 - acc: 1.0000 - val_loss: 0.0473 - val_acc: 0.9910\n",
            "Epoch 27/100\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 2.7772e-04 - acc: 1.0000 - val_loss: 0.0473 - val_acc: 0.9911\n",
            "Epoch 28/100\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 2.7716e-04 - acc: 1.0000 - val_loss: 0.0475 - val_acc: 0.9912\n",
            "Epoch 29/100\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 2.7662e-04 - acc: 1.0000 - val_loss: 0.0478 - val_acc: 0.9910\n",
            "Epoch 30/100\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 2.7607e-04 - acc: 1.0000 - val_loss: 0.0481 - val_acc: 0.9911\n",
            "Epoch 31/100\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 2.7576e-04 - acc: 1.0000 - val_loss: 0.0484 - val_acc: 0.9911\n",
            "Epoch 32/100\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 2.7535e-04 - acc: 1.0000 - val_loss: 0.0487 - val_acc: 0.9911\n",
            "Epoch 33/100\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 2.7502e-04 - acc: 1.0000 - val_loss: 0.0488 - val_acc: 0.9910\n",
            "Epoch 34/100\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 2.7468e-04 - acc: 1.0000 - val_loss: 0.0489 - val_acc: 0.9910\n",
            "Epoch 35/100\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 2.7451e-04 - acc: 1.0000 - val_loss: 0.0491 - val_acc: 0.9911\n",
            "Epoch 36/100\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 2.7420e-04 - acc: 1.0000 - val_loss: 0.0493 - val_acc: 0.9911\n",
            "Epoch 37/100\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 2.7396e-04 - acc: 1.0000 - val_loss: 0.0496 - val_acc: 0.9911\n",
            "Epoch 38/100\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 2.7377e-04 - acc: 1.0000 - val_loss: 0.0497 - val_acc: 0.9911\n",
            "Epoch 39/100\n",
            "60000/60000 [==============================] - 3s 53us/step - loss: 2.7354e-04 - acc: 1.0000 - val_loss: 0.0499 - val_acc: 0.9909\n",
            "Epoch 40/100\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 2.7337e-04 - acc: 1.0000 - val_loss: 0.0499 - val_acc: 0.9910\n",
            "Epoch 41/100\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 2.7324e-04 - acc: 1.0000 - val_loss: 0.0502 - val_acc: 0.9910\n",
            "Epoch 42/100\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 2.7313e-04 - acc: 1.0000 - val_loss: 0.0502 - val_acc: 0.9910\n",
            "Epoch 43/100\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 2.7296e-04 - acc: 1.0000 - val_loss: 0.0503 - val_acc: 0.9911\n",
            "Epoch 44/100\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 2.7278e-04 - acc: 1.0000 - val_loss: 0.0504 - val_acc: 0.9910\n",
            "Epoch 45/100\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 2.7271e-04 - acc: 1.0000 - val_loss: 0.0506 - val_acc: 0.9910\n",
            "Epoch 46/100\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 2.7256e-04 - acc: 1.0000 - val_loss: 0.0509 - val_acc: 0.9911\n",
            "Epoch 47/100\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 2.7248e-04 - acc: 1.0000 - val_loss: 0.0508 - val_acc: 0.9910\n",
            "Epoch 48/100\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 2.7229e-04 - acc: 1.0000 - val_loss: 0.0509 - val_acc: 0.9910\n",
            "Epoch 49/100\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 2.7226e-04 - acc: 1.0000 - val_loss: 0.0511 - val_acc: 0.9910\n",
            "Epoch 50/100\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 2.7216e-04 - acc: 1.0000 - val_loss: 0.0512 - val_acc: 0.9911\n",
            "Epoch 51/100\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 2.7205e-04 - acc: 1.0000 - val_loss: 0.0513 - val_acc: 0.9910\n",
            "Epoch 52/100\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 2.7195e-04 - acc: 1.0000 - val_loss: 0.0515 - val_acc: 0.9911\n",
            "Epoch 53/100\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 2.7189e-04 - acc: 1.0000 - val_loss: 0.0514 - val_acc: 0.9911\n",
            "Epoch 54/100\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 2.7181e-04 - acc: 1.0000 - val_loss: 0.0516 - val_acc: 0.9910\n",
            "Epoch 55/100\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 2.7174e-04 - acc: 1.0000 - val_loss: 0.0518 - val_acc: 0.9909\n",
            "Epoch 56/100\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 2.7166e-04 - acc: 1.0000 - val_loss: 0.0519 - val_acc: 0.9909\n",
            "Epoch 57/100\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 2.7159e-04 - acc: 1.0000 - val_loss: 0.0519 - val_acc: 0.9909\n",
            "Epoch 58/100\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 2.7154e-04 - acc: 1.0000 - val_loss: 0.0521 - val_acc: 0.9910\n",
            "Epoch 59/100\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 2.7147e-04 - acc: 1.0000 - val_loss: 0.0522 - val_acc: 0.9910\n",
            "Epoch 60/100\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 2.7141e-04 - acc: 1.0000 - val_loss: 0.0523 - val_acc: 0.9909\n",
            "Epoch 61/100\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 2.7134e-04 - acc: 1.0000 - val_loss: 0.0523 - val_acc: 0.9909\n",
            "Epoch 62/100\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 2.7130e-04 - acc: 1.0000 - val_loss: 0.0524 - val_acc: 0.9909\n",
            "Epoch 63/100\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 2.7124e-04 - acc: 1.0000 - val_loss: 0.0526 - val_acc: 0.9910\n",
            "Epoch 64/100\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 2.7120e-04 - acc: 1.0000 - val_loss: 0.0526 - val_acc: 0.9910\n",
            "Epoch 65/100\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 2.7115e-04 - acc: 1.0000 - val_loss: 0.0527 - val_acc: 0.9909\n",
            "Epoch 66/100\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 2.7109e-04 - acc: 1.0000 - val_loss: 0.0528 - val_acc: 0.9910\n",
            "Epoch 67/100\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 2.7105e-04 - acc: 1.0000 - val_loss: 0.0528 - val_acc: 0.9910\n",
            "Epoch 68/100\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 2.7101e-04 - acc: 1.0000 - val_loss: 0.0529 - val_acc: 0.9909\n",
            "Epoch 69/100\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 2.7097e-04 - acc: 1.0000 - val_loss: 0.0530 - val_acc: 0.9910\n",
            "Epoch 70/100\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 2.7092e-04 - acc: 1.0000 - val_loss: 0.0530 - val_acc: 0.9910\n",
            "Epoch 71/100\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 2.7088e-04 - acc: 1.0000 - val_loss: 0.0531 - val_acc: 0.9910\n",
            "Epoch 72/100\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 2.7085e-04 - acc: 1.0000 - val_loss: 0.0531 - val_acc: 0.9909\n",
            "Epoch 73/100\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 2.7080e-04 - acc: 1.0000 - val_loss: 0.0534 - val_acc: 0.9910\n",
            "Epoch 74/100\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 2.7079e-04 - acc: 1.0000 - val_loss: 0.0533 - val_acc: 0.9909\n",
            "Epoch 75/100\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 2.7074e-04 - acc: 1.0000 - val_loss: 0.0534 - val_acc: 0.9909\n",
            "Epoch 76/100\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 2.7071e-04 - acc: 1.0000 - val_loss: 0.0535 - val_acc: 0.9909\n",
            "Epoch 77/100\n",
            "60000/60000 [==============================] - 3s 56us/step - loss: 2.7067e-04 - acc: 1.0000 - val_loss: 0.0535 - val_acc: 0.9910\n",
            "Epoch 78/100\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 2.7064e-04 - acc: 1.0000 - val_loss: 0.0536 - val_acc: 0.9909\n",
            "Epoch 79/100\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 2.7062e-04 - acc: 1.0000 - val_loss: 0.0537 - val_acc: 0.9909\n",
            "Epoch 80/100\n",
            "60000/60000 [==============================] - 3s 53us/step - loss: 2.7058e-04 - acc: 1.0000 - val_loss: 0.0538 - val_acc: 0.9909\n",
            "Epoch 81/100\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 2.7056e-04 - acc: 1.0000 - val_loss: 0.0538 - val_acc: 0.9910\n",
            "Epoch 82/100\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 2.7053e-04 - acc: 1.0000 - val_loss: 0.0539 - val_acc: 0.9909\n",
            "Epoch 83/100\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 2.7049e-04 - acc: 1.0000 - val_loss: 0.0539 - val_acc: 0.9910\n",
            "Epoch 84/100\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 2.7048e-04 - acc: 1.0000 - val_loss: 0.0540 - val_acc: 0.9909\n",
            "Epoch 85/100\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 2.7045e-04 - acc: 1.0000 - val_loss: 0.0541 - val_acc: 0.9909\n",
            "Epoch 86/100\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 2.7043e-04 - acc: 1.0000 - val_loss: 0.0541 - val_acc: 0.9909\n",
            "Epoch 87/100\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 2.7041e-04 - acc: 1.0000 - val_loss: 0.0542 - val_acc: 0.9909\n",
            "Epoch 88/100\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 2.7038e-04 - acc: 1.0000 - val_loss: 0.0542 - val_acc: 0.9909\n",
            "Epoch 89/100\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 2.7036e-04 - acc: 1.0000 - val_loss: 0.0543 - val_acc: 0.9909\n",
            "Epoch 90/100\n",
            "60000/60000 [==============================] - 3s 53us/step - loss: 2.7034e-04 - acc: 1.0000 - val_loss: 0.0543 - val_acc: 0.9909\n",
            "Epoch 91/100\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 2.7032e-04 - acc: 1.0000 - val_loss: 0.0544 - val_acc: 0.9909\n",
            "Epoch 92/100\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 2.7029e-04 - acc: 1.0000 - val_loss: 0.0545 - val_acc: 0.9908\n",
            "Epoch 93/100\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 2.7028e-04 - acc: 1.0000 - val_loss: 0.0545 - val_acc: 0.9909\n",
            "Epoch 94/100\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 2.7026e-04 - acc: 1.0000 - val_loss: 0.0546 - val_acc: 0.9909\n",
            "Epoch 95/100\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 2.7023e-04 - acc: 1.0000 - val_loss: 0.0546 - val_acc: 0.9909\n",
            "Epoch 96/100\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 2.7021e-04 - acc: 1.0000 - val_loss: 0.0547 - val_acc: 0.9908\n",
            "Epoch 97/100\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 2.7020e-04 - acc: 1.0000 - val_loss: 0.0548 - val_acc: 0.9908\n",
            "Epoch 98/100\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 2.7018e-04 - acc: 1.0000 - val_loss: 0.0548 - val_acc: 0.9908\n",
            "Epoch 99/100\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 2.7017e-04 - acc: 1.0000 - val_loss: 0.0548 - val_acc: 0.9908\n",
            "Epoch 100/100\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 2.7015e-04 - acc: 1.0000 - val_loss: 0.0549 - val_acc: 0.9909\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fad915acbe0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k81DDKDu2oHA",
        "colab_type": "code",
        "outputId": "d70e9275-434e-4b6b-86d1-053cf601cd6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        }
      },
      "source": [
        "data_ke=2\n",
        "\n",
        "image_test = x_test[data_ke]\n",
        "image_test = image_test.reshape(28,28)\n",
        "plt.imshow(image_test,'gray')\n",
        "plt.show()\n",
        "\n",
        "image_test = image_test.reshape(1,28,28,1)\n",
        "prediksi = model.predict(image_test)\n",
        "print('prediksi:'+str(np.argmax(prediksi)))\n",
        "print(prediksi)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAMEElEQVR4nO3dXYhc5R3H8d+vabwwepFUE4OKsRJR\nUUzKIoKhWnzBBiHmRoxQEiqsFwYi9KJiLxRKQaTaCy+EFcU0WF+IBqPWaBrEtDeaVVNNfIlWIias\nWSWCb4g1+fdiT8oad85s5pwzZ9z/9wPLzDzPnDl/DvnlOXNe5nFECMDM95O2CwDQH4QdSIKwA0kQ\ndiAJwg4k8dN+rsw2h/6BhkWEp2qvNLLbvtr2u7bft31rlc8C0Cz3ep7d9ixJeyRdKWmfpB2SVkXE\nWyXLMLIDDWtiZL9I0vsR8UFEfCvpUUkrKnwegAZVCfupkj6a9Hpf0fY9todtj9oerbAuABU1foAu\nIkYkjUjsxgNtqjKy75d0+qTXpxVtAAZQlbDvkLTY9pm2j5N0vaTN9ZQFoG4978ZHxHe210p6XtIs\nSQ9GxO7aKgNQq55PvfW0Mr6zA41r5KIaAD8ehB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKE\nHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4k0dcpm5HP2Wef3bHvnXfe\nKV123bp1pf333ntvTzVlxcgOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0lwnh2NWrp0ace+w4cPly67\nb9++ustJrVLYbe+V9IWkQ5K+i4ihOooCUL86RvZfRcSnNXwOgAbxnR1IomrYQ9ILtl+1PTzVG2wP\n2x61PVpxXQAqqLobvywi9tueL2mr7XciYvvkN0TEiKQRSbIdFdcHoEeVRvaI2F88jkvaJOmiOooC\nUL+ew257ju0TjzyXdJWkXXUVBqBeVXbjF0jaZPvI5/wtIrbUUhVmjCVLlnTs++qrr0qX3bRpU93l\npNZz2CPiA0kX1lgLgAZx6g1IgrADSRB2IAnCDiRB2IEkuMUVlZx//vml/WvXru3Yt2HDhrrLQQlG\ndiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgvPsqOScc84p7Z8zZ07Hvscee6zuclCCkR1IgrADSRB2\nIAnCDiRB2IEkCDuQBGEHknBE/yZpYUaYmeeVV14p7T/55JM79nW7F77bT01jahHhqdoZ2YEkCDuQ\nBGEHkiDsQBKEHUiCsANJEHYgCe5nR6lFixaV9g8NDZX279mzp2Mf59H7q+vIbvtB2+O2d01qm2d7\nq+33ise5zZYJoKrp7MY/JOnqo9pulbQtIhZL2la8BjDAuoY9IrZLOnhU8wpJ64vn6yVdW3NdAGrW\n63f2BRExVjz/WNKCTm+0PSxpuMf1AKhJ5QN0ERFlN7hExIikEYkbYYA29Xrq7YDthZJUPI7XVxKA\nJvQa9s2SVhfPV0t6qp5yADSl62687UckXSbpJNv7JN0u6U5Jj9u+UdKHkq5rski059JLL620/Cef\nfFJTJaiqa9gjYlWHrstrrgVAg7hcFkiCsANJEHYgCcIOJEHYgSS4xRWlLrjggkrL33XXXTVVgqoY\n2YEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCaZsTu7iiy8u7X/22WdL+/fu3Vvaf8kll3Ts++abb0qX\nRW+YshlIjrADSRB2IAnCDiRB2IEkCDuQBGEHkuB+9uSuuOKK0v558+aV9m/ZsqW0n3Ppg4ORHUiC\nsANJEHYgCcIOJEHYgSQIO5AEYQeS4Dx7chdeeGFpf7ffO9i4cWOd5aBBXUd22w/aHre9a1LbHbb3\n295Z/C1vtkwAVU1nN/4hSVdP0f6XiFhS/P293rIA1K1r2CNiu6SDfagFQIOqHKBba/uNYjd/bqc3\n2R62PWp7tMK6AFTUa9jvk3SWpCWSxiTd3emNETESEUMRMdTjugDUoKewR8SBiDgUEYcl3S/ponrL\nAlC3nsJue+Gklysl7er0XgCDoevvxtt+RNJlkk6SdEDS7cXrJZJC0l5JN0XEWNeV8bvxfXfKKaeU\n9u/cubO0/7PPPivtP/fcc4+5JjSr0+/Gd72oJiJWTdH8QOWKAPQVl8sCSRB2IAnCDiRB2IEkCDuQ\nBLe4znBr1qwp7Z8/f35p/3PPPVdjNWgTIzuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJMF59hnujDPO\nqLR8t1tc8ePByA4kQdiBJAg7kARhB5Ig7EAShB1IgrADSXCefYa75pprKi3/9NNP11QJ2sbIDiRB\n2IEkCDuQBGEHkiDsQBKEHUiCsANJcJ59Bli2bFnHvm5TNiOPriO77dNtv2j7Ldu7ba8r2ufZ3mr7\nveJxbvPlAujVdHbjv5P0u4g4T9LFkm62fZ6kWyVti4jFkrYVrwEMqK5hj4ixiHiteP6FpLclnSpp\nhaT1xdvWS7q2qSIBVHdM39ltL5K0VNLLkhZExFjR9bGkBR2WGZY03HuJAOow7aPxtk+Q9ISkWyLi\n88l9ERGSYqrlImIkIoYiYqhSpQAqmVbYbc/WRNAfjogni+YDthcW/QsljTdTIoA6dN2Nt21JD0h6\nOyLumdS1WdJqSXcWj081UiG6WrlyZce+WbNmlS77+uuvl/Zv3769p5oweKbznf0SSb+R9KbtnUXb\nbZoI+eO2b5T0oaTrmikRQB26hj0i/iXJHbovr7ccAE3hclkgCcIOJEHYgSQIO5AEYQeS4BbXH4Hj\njz++tH/58uU9f/bGjRtL+w8dOtTzZ2OwMLIDSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKe+JGZPq3M\n7t/KZpDZs2eX9r/00ksd+8bHy39T5IYbbijt//rrr0v7MXgiYsq7VBnZgSQIO5AEYQeSIOxAEoQd\nSIKwA0kQdiAJzrMDMwzn2YHkCDuQBGEHkiDsQBKEHUiCsANJEHYgia5ht3267Rdtv2V7t+11Rfsd\ntvfb3ln89f7j5QAa1/WiGtsLJS2MiNdsnyjpVUnXamI+9i8j4s/TXhkX1QCN63RRzXTmZx+TNFY8\n/8L225JOrbc8AE07pu/sthdJWirp5aJpre03bD9oe26HZYZtj9oerVQpgEqmfW287RMkvSTpTxHx\npO0Fkj6VFJL+qIld/d92+Qx244GGddqNn1bYbc+W9Iyk5yPinin6F0l6JiLO7/I5hB1oWM83wti2\npAckvT056MWBuyNWStpVtUgAzZnO0fhlkv4p6U1Jh4vm2yStkrREE7vxeyXdVBzMK/ssRnagYZV2\n4+tC2IHmcT87kBxhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYg\nia4/OFmzTyV9OOn1SUXbIBrU2ga1LonaelVnbWd06ujr/ew/WLk9GhFDrRVQYlBrG9S6JGrrVb9q\nYzceSIKwA0m0HfaRltdfZlBrG9S6JGrrVV9qa/U7O4D+aXtkB9AnhB1IopWw277a9ru237d9axs1\ndGJ7r+03i2moW52frphDb9z2rklt82xvtf1e8TjlHHst1TYQ03iXTDPe6rZre/rzvn9ntz1L0h5J\nV0raJ2mHpFUR8VZfC+nA9l5JQxHR+gUYtn8p6UtJfz0ytZbtuyQdjIg7i/8o50bE7wektjt0jNN4\nN1Rbp2nG16jFbVfn9Oe9aGNkv0jS+xHxQUR8K+lRSStaqGPgRcR2SQePal4haX3xfL0m/rH0XYfa\nBkJEjEXEa8XzLyQdmWa81W1XUldftBH2UyV9NOn1Pg3WfO8h6QXbr9oebruYKSyYNM3Wx5IWtFnM\nFLpO491PR00zPjDbrpfpz6viAN0PLYuIX0j6taSbi93VgRQT38EG6dzpfZLO0sQcgGOS7m6zmGKa\n8Sck3RIRn0/ua3PbTVFXX7ZbG2HfL+n0Sa9PK9oGQkTsLx7HJW3SxNeOQXLgyAy6xeN4y/X8X0Qc\niIhDEXFY0v1qcdsV04w/IenhiHiyaG59201VV7+2Wxth3yFpse0zbR8n6XpJm1uo4wdszykOnMj2\nHElXafCmot4saXXxfLWkp1qs5XsGZRrvTtOMq+Vt1/r05xHR9z9JyzVxRP4/kv7QRg0d6vq5pH8X\nf7vbrk3SI5rYrfuvJo5t3CjpZ5K2SXpP0j8kzRug2jZoYmrvNzQRrIUt1bZME7vob0jaWfwtb3vb\nldTVl+3G5bJAEhygA5Ig7EAShB1IgrADSRB2IAnCDiRB2IEk/gciQMnFg+KOfAAAAABJRU5ErkJg\ngg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "prediksi:1\n",
            "[[7.1599828e-19 1.0000000e+00 5.5466509e-18 1.6965400e-23 2.1328969e-14\n",
            "  5.2279072e-22 4.5413462e-19 1.3525484e-15 9.5483847e-12 6.9415100e-22]]\n",
            "prediksi:3\n",
            "[[7.1599828e-19 1.0000000e+00 5.5466509e-18 1.6965400e-23 2.1328969e-14\n",
            "  5.2279072e-22 4.5413462e-19 1.3525484e-15 9.5483847e-12 6.9415100e-22]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAp1zsKgCoy-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}